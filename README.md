# Self-Supervised Learning for Prostate Cancer Grading (SICAPv2)

This project implements a **Self-Supervised Learning (SSL)** framework for histopathological image analysis, specifically targeting prostate cancer grading using the **SICAPv2 dataset**.

## Project Overview

The goal is to leverage unlabeled data to learn robust feature representations of prostate tissue. This is achieved through a **Generative SSL** approach (Convolutional Autoencoder) as a pretext task, followed by downstream classification.

* **Dataset:** [SICAPv2](https://data.mendeley.com/datasets/9xxm58dvs3/1) (Prostate Cancer Histopathology).
* **Method:** A tailored Convolutional Autoencoder (CAE) with skip connections and a ResNet-like bottleneck.
* **Pretext Task:** Image reconstruction (learning spatial features without labels).
* **Downstream Task:** Gleason Grading (Classification of NC, G3, G4, G5).

## Project Structure

```text
.
├── dataset/                  # Dataset folder (not included in repo, see Setup)
│   ├── images/               # Raw .jpg patches
│   ├── partition/            # Excel files defining Train/Test splits
│   ├── Train.csv             # Generated by setup_data.py
│   └── Test.csv              # Generated by setup_data.py
├── output/                   # Stores trained models and logs
├── Main.py                   # Main script for training the SSL Pretext Task
├── variational_autoencoder.py# Model architecture (Encoder/Decoder)
├── my_data_generator.py      # Custom data loader
├── setup_data.py             # Script to parse SICAPv2 excel files into CSVs
└── utils_huleo.py            # Helper functions for augmentation
```

## Setup Instructions

### 1. Prerequisites
Ensure you have Python installed (3.8+ recommended). Then, install the required dependencies:

```bash
pip install -r requirements.txt
```
### 2. Download the Dataset

* Download the SICAPv2 dataset from Mendeley Data.
* Extract the downloaded zip file directly into the dataset/ folder in your project root.
* Ensure your folder structure looks like this:
* dataset/images/ 
* dataset/partition/ (Should contain .xlsx files defining the train/test split)

### 3. Generate CSV Labels

* The training code requires specific CSV files (Train.csv and Test.csv) to map images to their cancer grades. The raw dataset comes with Excel files that the code cannot read by default.
* Run the provided setup script to automatically generate these files:

```Bash
python setup_data.py
```
What this does:

* Scans the dataset/partition/ folder.
* Converts the raw Excel files into dataset/Train.csv and dataset/Test.csv.
* Formats the columns to match the model's expected One-Hot Encoding (NC, G3, G4, G5).

### 4. Configure Training (Optional)

* Open Main.py to adjust training hyperparameters if needed:
* Batch Size: Set to 16 by default. If you run out of memory (OOM error), lower it to 8.
* GPU Settings: The code defaults to using GPU 0. If you are running on CPU, comment out the line os.environ["CUDA_VISIBLE_DEVICES"] = "0".

## Usage
Phase 1: Pretext Task (SSL Training)
To train the Convolutional Autoencoder (CAE) on the unlabeled image patches:

```Bash
python Main.py
```
## Output:

* Weights: The pre-trained encoder weights are saved to: output/models/exp_XXXX/weights/VAE_weights.weights.h5
* Loss Plot: A graph showing reconstruction loss is saved to: output/models/exp_XXXX/viz/training_loss.png
* Reconstructions: "Before vs. After" images are saved to the results folder to visually verify the SSL performance.

### Phase 2: Downstream Task (Classification)
(Note: This requires the pre-trained weights generated in Phase 1)

To fine-tune the model for Gleason Grading (classifying NC vs. G3 vs. G4 vs. G5):

* Open fine_tune.py.
* Update the WEIGHTS_PATH variable (line ~21) to point to your best .weights.h5 file from Phase 1.
* Run the classification training:

```Bash
python fine_tune.py
```

## Output:

* Final Model: Saved as output/final_classifier.keras.
* Performance Plot: An accuracy/loss graph saved as output/classification_results.png