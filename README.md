# Self-Supervised Learning for Prostate Cancer Grading (SICAPv2)

**CP8321 Deep Learning - Final Project**  
**Toronto Metropolitan University (Ryerson University)**

This project implements and compares **three Self-Supervised Learning (SSL)** approaches for histopathological image analysis, specifically targeting prostate cancer Gleason grading using the **SICAPv2 dataset**.

## Project Overview

The goal is to demonstrate how self-supervised pretraining improves deep learning performance on medical imaging tasks with limited labeled data. We compare three approaches:

1. **Baseline (No SSL):** Classifier trained from scratch with random initialization
2. **Autoencoder-SSL:** Reconstruction-based SSL using Convolutional Autoencoder
3. **SimCLR-SSL:** Contrastive learning using SimCLR framework ‚ú® (Assignment Requirement)

### Key Information

* **Dataset:** [SICAPv2](https://data.mendeley.com/datasets/9xxm58dvs3/1) - Prostate Cancer Histopathology (~18,000 patches)
* **Task:** Gleason Grading (4-class classification: NC, G3, G4, G5)
* **Methods:** Three SSL approaches + comprehensive comparison
* **Image Size:** 128√ó128√ó3 RGB patches (following paper specification)

## Literature Review & Motivation

This project is grounded in recent advances in self-supervised learning for medical imaging:

### Foundational Papers

1. **Ciga, Xu & Martel (2020) - "Self-Supervised Contrastive Learning for Digital Histopathology"** [[arXiv]](https://arxiv.org/abs/2011.13971)
   - **Key Finding:** Domain-specific SSL (trained on histopathology) outperforms ImageNet pretraining
   - **Method:** SimCLR adapted for 57 histopathology datasets
   - **Impact:** Established contrastive learning as state-of-the-art for histopathology

2. **Stacke et al. (2021) - "Learning Representations with Contrastive Self-Supervised Learning for Histopathology"** [[arXiv]](https://arxiv.org/abs/2112.05760)
   - **Key Finding:** Histopathology requires different augmentations than natural images
   - **Critical Insight:** Color jittering essential due to stain variation
   - **Our Implementation:** Strong color augmentation (¬±40% brightness/contrast/saturation)

3. **Efficient Self-Supervised Grading of Prostate Cancer (2025)** [[arXiv]](https://arxiv.org/abs/2501.15520)
   - **Dataset:** Uses SICAP (same as this project!) üéØ
   - **Method:** Task-specific SSL with stain-agnostic features
   - **Relevance:** Direct baseline for comparison

4. **Kang et al. (2023) - "Benchmarking Self-Supervised Learning on Diverse Pathology Datasets"** [[arXiv]](https://arxiv.org/abs/2212.04690)
   - **Finding:** Domain-aligned SSL consistently improves performance
   - **Conclusion:** Medical imaging benefits more from task-specific SSL than general pretraining

### Our Approach

We implement and compare:
- **Reconstruction-based SSL** (Autoencoder): Learns texture/structure features
- **Contrastive SSL** (SimCLR): Learns discriminative features via positive/negative pairs
- **Baseline**: No pretraining (demonstrates SSL benefit)

**Hypothesis:** Contrastive learning will outperform reconstruction-based SSL for classification tasks, as predicted by recent literature.

---

## Project Structure

```text
.
‚îú‚îÄ‚îÄ dataset/                      # Dataset (download separately)
‚îÇ   ‚îú‚îÄ‚îÄ images/                   # Raw histopathology patches (.jpg)
‚îÇ   ‚îú‚îÄ‚îÄ partition/                # Excel files (Train/Test splits)
‚îÇ   ‚îú‚îÄ‚îÄ Train.csv                 # Generated by setup_data.py
‚îÇ   ‚îî‚îÄ‚îÄ Test.csv                  # Generated by setup_data.py
‚îÇ
‚îú‚îÄ‚îÄ output/                       # Training outputs
‚îÇ   ‚îú‚îÄ‚îÄ baseline/                 # Baseline model results
‚îÇ   ‚îú‚îÄ‚îÄ simclr/                   # SimCLR model results
‚îÇ   ‚îî‚îÄ‚îÄ models/                   # Autoencoder model results
‚îÇ
‚îú‚îÄ‚îÄ Main.py                       # Autoencoder SSL pretraining
‚îú‚îÄ‚îÄ simclr_pretrain.py           # SimCLR SSL pretraining ‚≠ê
‚îú‚îÄ‚îÄ train_baseline.py            # Baseline training (no SSL)
‚îÇ
‚îú‚îÄ‚îÄ fine_tune.py                 # Autoencoder fine-tuning
‚îú‚îÄ‚îÄ fine_tune_simclr.py          # SimCLR fine-tuning ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ evaluate_final.py            # Autoencoder evaluation
‚îú‚îÄ‚îÄ evaluate_simclr.py           # SimCLR evaluation ‚≠ê
‚îú‚îÄ‚îÄ evaluate_baseline.py         # Baseline evaluation ‚≠ê
‚îú‚îÄ‚îÄ compare_all_models.py        # Comprehensive comparison ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ variational_autoencoder.py   # Encoder/Decoder architecture
‚îú‚îÄ‚îÄ simclr_model.py              # SimCLR model + NT-Xent loss ‚≠ê
‚îú‚îÄ‚îÄ simclr_augmentations.py      # Strong augmentation pipeline ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ my_data_generator.py         # Custom data generator
‚îú‚îÄ‚îÄ data_augmentation.py         # Augmentation utilities
‚îú‚îÄ‚îÄ setup_data.py                # Dataset preprocessing
‚îú‚îÄ‚îÄ utils_*.py                   # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ GPU_TRAINING_GUIDE.md        # Instructions for GPU training ‚≠ê
‚îú‚îÄ‚îÄ Model_architecture.md        # Detailed architecture docs
‚îî‚îÄ‚îÄ notes.md                     # Experiment log

‚≠ê = New files for this project
```

## Setup Instructions

### 1. Prerequisites
Ensure you have Python installed (3.8+ recommended). Then, install the required dependencies:

```bash
pip install -r requirements.txt
```
### 2. Download the Dataset

* Download the SICAPv2 dataset from Mendeley Data.
* Extract the downloaded zip file directly into the dataset/ folder in your project root.
* Ensure your folder structure looks like this:
* dataset/images/ 
* dataset/partition/ (Should contain .xlsx files defining the train/test split)

### 3. Generate CSV Labels

* The training code requires specific CSV files (Train.csv and Test.csv) to map images to their cancer grades. The raw dataset comes with Excel files that the code cannot read by default.
* Run the provided setup script to automatically generate these files:

```Bash
python setup_data.py
```
What this does:

* Scans the dataset/partition/ folder.
* Converts the raw Excel files into dataset/Train.csv and dataset/Test.csv.
* Formats the columns to match the model's expected One-Hot Encoding (NC, G3, G4, G5).

### 4. Configure Training (Optional)

* Open Main.py to adjust training hyperparameters if needed:
* Batch Size: Set to 16 by default. If you run out of memory (OOM error), lower it to 8.
* GPU Settings: The code defaults to using GPU 0. If you are running on CPU, comment out the line os.environ["CUDA_VISIBLE_DEVICES"] = "0".

## Usage

### Training Pipeline

We provide three complete training pipelines for comparison:

---

### **Approach 1: Baseline (No SSL - Train from Scratch)**

Train a classifier with random weight initialization (no pretraining).

```bash
python train_baseline.py
```

**Output:**
- Model: `./output/baseline/best_baseline_classifier.keras`
- Training curves: `./output/baseline/training_curves.png`
- Training time: ~1-2 hours (GPU)

**Purpose:** Establishes baseline performance to measure SSL improvement.

---

### **Approach 2: Autoencoder-SSL (Reconstruction-based)**

#### Step 1: SSL Pretraining
Train autoencoder to reconstruct images (unsupervised):

```bash
python Main.py
```

**Output:**
- Encoder weights: `./output/models/exp_XXXX/weights/VAE_weights.weights.h5`
- Reconstructions: `./output/models/exp_XXXX/viz/`
- Training time: ~1-2 hours (GPU)

#### Step 2: Fine-tuning
Load pretrained encoder and train classifier:

```bash
# Edit fine_tune.py: Set WEIGHTS_PATH to your exp_XXXX path
python fine_tune.py
```

**Output:**
- Classifier: `./output/final_classifier.keras`
- Results: `./output/classification_results.png`
- Training time: ~1 hour (GPU)

---

### **Approach 3: SimCLR-SSL (Contrastive Learning)** ‚≠ê **RECOMMENDED**

#### Step 1: SimCLR Pretraining
Train encoder using contrastive learning (unsupervised):

```bash
python simclr_pretrain.py
```

**Output:**
- Encoder weights: `./output/simclr/encoder_weights.h5`
- Training curves: `./output/simclr/training_curves.png`
- Training time: ~2-3 hours (GPU)

**What it does:**
- Creates two augmented views of each image
- Learns to maximize similarity between views of same image
- Learns to minimize similarity between different images
- No labels required!

#### Step 2: Fine-tuning
Load SimCLR encoder and train classifier:

```bash
python fine_tune_simclr.py
```

**Output:**
- Classifier: `./output/simclr/best_simclr_classifier.keras`
- Results: `./output/simclr/classification_results.png`
- Training time: ~1 hour (GPU)

---

### **Evaluation & Comparison**

#### Evaluate Each Model
```bash
python evaluate_baseline.py    # Baseline metrics
python evaluate_final.py        # Autoencoder metrics
python evaluate_simclr.py       # SimCLR metrics
```

#### Compare All Three
```bash
python compare_all_models.py
```

**Output:**
- Comparison table: `./output/model_comparison.csv`
- Comparison plots: `./output/model_comparison_plots.png`
- Summary report: `./output/comparison_report.txt`

**Generates:**
- Accuracy comparison
- Per-class performance
- F1-scores, Cohen's Kappa
- ROC curves
- SSL improvement metrics

---

### Quick Start (Google Colab Pro) üöÄ

**Recommended for GPU training!**

1. Upload dataset to Google Drive
2. Open [Google Colab](https://colab.research.google.com/)
3. Clone this repo:
```python
!git clone https://github.com/yourusername/SSL_Prostate_Cancer_Grading.git
%cd SSL_Prostate_Cancer_Grading
```
4. Run training scripts (see [GPU_TRAINING_GUIDE.md](GPU_TRAINING_GUIDE.md))

**Estimated time on Colab Pro:**
- T4 GPU (Free): 4-6 hours total
- A100 GPU (Pro): 2-3 hours total

---## Results & Comparison

### Performance Summary

| Model | Overall Accuracy | Macro F1 | Weighted F1 | Cohen's Kappa |
|-------|-----------------|----------|-------------|---------------|
| **Baseline (No SSL)** | TBD | TBD | TBD | TBD |
| **Autoencoder-SSL** | 62.8% | 0.39 | 0.62 | 0.50 |
| **SimCLR-SSL** | TBD | TBD | TBD | TBD |

*TBD = To be determined after GPU training*

### Per-Class Performance (Autoencoder-SSL)

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| **NC (Non-Cancerous)** | 0.80 | 0.85 | 0.83 | 1727 |
| **G3 (Gleason 3)** | 0.14 | 0.13 | 0.13 | 497 |
| **G4 (Gleason 4)** | 0.54 | 0.65 | 0.59 | 1042 |
| **G5 (Gleason 5)** | 0.00 | 0.00 | 0.00 | 247 |

**Key Observations:**
- ‚úÖ Strong performance on majority class (NC: 85% recall)
- ‚ö†Ô∏è Moderate performance on G4 (65% recall)
- ‚ùå Poor performance on minority classes (G3: 13%, G5: 0%)
- üìä Class imbalance is the primary challenge

### Expected Improvements with SimCLR

Based on literature (Ciga et al., 2020; Kang et al., 2023):
- **Overall Accuracy:** Expected +5-10% over Autoencoder
- **Minority Classes:** Expected +10-15% recall for G3/G5
- **Reason:** Contrastive learning forces discriminative features, while reconstruction focuses on texture similarity

---

## Methodology & Architecture

### Why Three Approaches?

1. **Baseline (No SSL):** Demonstrates the value of pretraining
2. **Autoencoder:** Reconstruction-based SSL (learns texture/structure)
3. **SimCLR:** Contrastive SSL (learns discriminative features) - **Assignment Requirement**

### SimCLR Framework (Our Implementation)

```
Input Image (128√ó128√ó3)
     ‚Üì
[Data Augmentation Pipeline]
     ‚îú‚îÄ‚Üí View 1 (Strong augmentation)
     ‚îî‚îÄ‚Üí View 2 (Different strong augmentation)
     ‚Üì
[Shared Encoder]
     ‚îú‚îÄ‚Üí Features 1 (256-dim)
     ‚îî‚îÄ‚Üí Features 2 (256-dim)
     ‚Üì
[Projection Head]
     ‚îú‚îÄ‚Üí Embedding 1 (128-dim)
     ‚îî‚îÄ‚Üí Embedding 2 (128-dim)
     ‚Üì
[NT-Xent Loss]
  Goal: Maximize similarity(emb1, emb2)
        Minimize similarity(emb1, other_embeddings)
```

**Key Innovation:** No labels needed! The model learns by identifying which augmented views belong to the same image.

### Augmentation Pipeline (Critical for Histopathology)

Following Stacke et al. (2021) recommendations:

**Strong Augmentations:**
- ‚úì Color jittering (¬±40% brightness/contrast/saturation, ¬±10% hue)
- ‚úì Random crops (80-100% of image)
- ‚úì Geometric transforms (flips, 90¬∞ rotations)
- ‚úì Gaussian blur (50% probability)

**Why so strong?**
- Histopathology has high stain variation
- Model must learn stain-invariant features
- Stronger augmentation ‚Üí better generalization

### Encoder Architecture

**Convolutional Encoder (Shared across all methods):**
```python
Input: 128√ó128√ó3
  ‚Üì Conv2D(16, stride=2) + BatchNorm + LeakyReLU + Dropout
  ‚Üì Conv2D(32, stride=2)
  ‚Üì Conv2D(64, stride=2) ‚Üê Skip connection saved
  ‚Üì Conv2D(128, stride=2)
  ‚Üì Conv2D(256, stride=2)
  ‚Üì Bottleneck: Conv2D(128) ‚Üí Conv2D(64) ‚Üí Conv2D(128)
  ‚Üì Flatten ‚Üí Dense(256)
Output: 256 features
```

**For Classification:**
```python
Encoder features (256-dim)
  ‚Üì GlobalMaxPooling2D ‚Üí Dense(200, ReLU)
  ‚Üì Dense(4, Softmax)
Output: [NC, G3, G5, G4] probabilities
```

### Training Strategy

**SSL Pretraining:**
- Epochs: 30 (SimCLR), 15 (Autoencoder)
- Batch Size: 64 (SimCLR), 16 (Autoencoder)
- Optimizer: Adam with cosine learning rate decay
- Temperature: 0.5 (SimCLR NT-Xent loss)

**Fine-tuning:**
- Two-stage: Frozen encoder (50 epochs) ‚Üí Optional unfrozen (0-50 epochs)
- Loss: Focal loss (Œ±=0.5, Œ≥=2.0) for class imbalance
- Optimizer: SGD with momentum=0.9, clipnorm=1.0
- Learning Rate: 1e-5 (stage 1), 5e-5 (stage 2)

### Class Imbalance Handling

**Challenge:** Dataset is heavily imbalanced
- NC: 49% (majority)
- G4: 30%
- G3: 14%
- G5: 7% (minority)

**Solutions Implemented:**
1. **Focal Loss:** Down-weights easy examples, focuses on hard cases
2. **Data Augmentation:** Increases effective training samples
3. **Gradient Clipping:** Prevents training instability

**Not Used:** Class weights (caused training collapse in experiments)

---

## Methodological Note

### Assignment Requirement: Contrastive Learning

**Assignment Specification:**
> "Implement SSL techniques like contrastive learning (SimCLR, MoCo)..."

**Our Implementation:**
‚úÖ **Primary Method:** SimCLR (full implementation in `simclr_*.py`)  
‚úÖ **Comparison:** Baseline and Autoencoder for comprehensive study  
‚úÖ **Literature-Grounded:** Based on Ciga et al. (2020) and Stacke et al. (2021)  

**Autoencoder vs. SimCLR:**
- **Autoencoder:** Learns to reconstruct images ‚Üí good for texture/structure
- **SimCLR:** Learns discriminative features ‚Üí better for classification
- **Expectation:** SimCLR will outperform Autoencoder (validated in literature)

This comprehensive comparison strengthens the project by showing:
1. SSL improves over baseline (demonstrates pretraining value)
2. Contrastive SSL > Reconstruction SSL (validates assignment focus)

---

## References

1. Ciga, O., Xu, T., & Martel, A. L. (2020). Self-supervised contrastive learning for digital histopathology. *arXiv preprint arXiv:2011.13971*. https://arxiv.org/abs/2011.13971

2. Stacke, K., Unger, J., Lundstr√∂m, C., & Eilertsen, G. (2021). Learning representations with contrastive self-supervised learning for histopathology applications. *arXiv preprint arXiv:2112.05760*. https://arxiv.org/abs/2112.05760

3. Kang, M., Song, H., Park, S., Yoo, D., & Pereira, S. (2023). Benchmarking self-supervised learning on diverse pathology datasets. *arXiv preprint arXiv:2212.04690*. https://arxiv.org/abs/2212.04690

4. Efficient self-supervised grading of prostate cancer pathology. (2025). *arXiv preprint arXiv:2501.15520*. https://arxiv.org/abs/2501.15520

5. Silva-Rodr√≠guez, J., Colomer, A., Sales, M. A., Molina, R., & Naranjo, V. (2020). Going deeper through the Gleason scoring scale: An automatic end-to-end system for histology prostate grading and cribriform pattern detection. *Computer Methods and Programs in Biomedicine*, 195, 105637.

---

## Project Team

**Authors:**
- Parsa Ranjbaran (Student ID: 501037874)
- Abdur Qadeer (Student ID: 500967819)
- Satvik Kaul (Student ID: 501312329)

**Course:** CP8321 Deep Learning  
**Institution:** Toronto Metropolitan University (Ryerson University)  
**Term:** Fall 2025

---

## License

This project is for educational purposes as part of CP8321 Deep Learning course requirements.

---

## Acknowledgments

- SICAPv2 Dataset creators for providing high-quality annotated histopathology images
- TensorFlow and Keras teams for excellent deep learning frameworks
- Research community for pioneering work in self-supervised learning for medical imaging
